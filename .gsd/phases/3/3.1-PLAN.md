---
phase: 3
plan: 1
wave: 1
---

# Plan 3.1: UMAP Caching Logic

## Objective
Implement an LRU Caching mechanism for `compute_umap_embeddings` in `arranger.py`. This will persist the expensive dimensionality reduction results when the user tweaks HDBSCAN sliders (which don't change the UMAP manifold).

## Context
- wildcards_gen/core/arranger.py

## Tasks

<task type="auto">
  <name>Implement Hash and Cache</name>
  <files>wildcards_gen/core/arranger.py</files>
  <action>
    1. Implement helper `_hash_array(arr: np.ndarray) -> str` using SHA256 of the buffer.
    2. Add `_UMAP_CACHE` (Dict) and `_UMAP_CACHE_MAX_SIZE` (const 10).
    3. Modify `compute_umap_embeddings` to check cache before computing.
       Key components: (hash(embeddings), n_neighbors, min_dist, n_components).
       If miss -> compute -> evict if full -> store.
  </action>
  <verify>grep "_hash_array" wildcards_gen/core/arranger.py</verify>
  <done>Caching logic implemented</done>
</task>

<task type="auto">
  <name>Verify Determinism</name>
  <files>tests/test_arranger_caching.py</files>
  <action>
    Create a new test file `tests/test_arranger_caching.py`:
    - Test `_hash_array` returns same hash for duplicate array.
    - Test `compute_umap_embeddings` returns identical object (or cached value) on second call.
    - Verify computation time drops on second call.
  </action>
  <verify>uv run pytest tests/test_arranger_caching.py</verify>
  <done>Tests confirm caching works</done>
</task>

## Success Criteria
- [ ] `compute_umap_embeddings` does not re-run UMAP when called sequentially with same inputs.
- [ ] Changing HDBSCAN params (which don't affect UMAP inputs) is fast.
